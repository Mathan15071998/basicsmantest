                        Manual Testing Basics
                    
what is software?
    It is a collection of programs written by developers to perform the task.

    types of softwares:
    1)Applications- it's the applications we use regularly
        a)website apps like flipkart/amazon
        b)deckstop and mobile apps.

    2)System softwares- like OS / system drivers and servers which used to run the system.

    3)Compilers/debuggers- softwares used by developers to write the code to perform oprations.

What is software testing?
    Software testing is a software development process where the quality of the software is tested. The reason behind this 
act is to make sure we deliver quality software to the cxs.

    Parameters for the quality software:
    a)No/minimal bugs which not affects clients regular tasks.
    b)meets all the requirements of the clients which specified in the Customer  Requirement Document.
    c)Delivered on time within the specified budget.
    d)user-friendly and maintenable(if any issue occured, it should be mostly solved from clients end.)

Project vs product?

    Project-Software specifically developed for the clients and/ or their customers(for the sole use of clients discretion)
    Product- Software developed based on the demand from the market for people's use, this software can be
     utilized by anyone.

Errors, bugs and failure of the software?

    Errors- if bug found from developers end.
    failure- if bug found while testing.
    Software- if bug found from clients end.

Why does the software has bugs?
    1)lack of communication/no communication bw testers and developers.
    2)lack of skilled testers.
    3)software complexity(if software has end number of modules, then there are chances for bug when a/few modules missed from testing.)
    3)when clients often change their requirments during the software development cycle.

what is SDLC?
    Software Development Life Cycle is a process used by IT industry to design, develop and test the software.

    Types of model in SDLC:
        1)Waterfall model:
            In this model, first phase is requirement analysis(gathering the needs of clients), followed by designing the
        software, developing and testing the software. Finally software will be deployed at cx's environment and then
        maintenance(pushed for production.). This model is preferred for small projects.

        Pros in this model:
            1)since no requirement changes are allowed, less no of bugs/no bugs is the outcome.
            2)Investment is less, 'cause we can hire the concerned department only when they needed.

         Cons in this model:
            1)Testing is carried only at the end of cycle, there is no verification/validation at the beginning/mid 
            of the cycle.
            2)Will take much time,'cause the work of another department will be started only after previous department
             given their output.

        2)Spiral Model:
            The similar to the waterfall model, like first, requirement will be collected from cx.
            then software prototype will be prepared, then real software will be developed only when clients satisfied within
            the prototype.  Once cx agreed,software will be designed followed before development.
            Finally software will be tested by testers and clients. Then it will enter into the production when clients agreed.
            This model is preferred for product kind of softwares and when there is dependency for modules and versions, this
            type is preferred.
        Pros in this model:
            1)Clients can change their requirements.
            2)prototype is an advantage- the real software is prepared only when cx satisfied with the prototype.(so we can
            take this as a verification/testing at early stage.)
            3)Each time at the end of a software cycle, new version of the software is realeased.

        Cons in this model:
            1)No testing at all stages.
            2)clients can change their needs only after the end of cycle, can't change during software development process.
            3)same as the waterfall model, one department input become another department's output, so will take more time.

        3)V or V-V model:
            This model is different compared to other two, first BRS/CRS/URS is prepared by business people.
            Followed by BRS(Non-technical doument contains client's needs.), SRS(Technical document which contains
            needs of the client, which become input for developers,designers and testers input to start 
            their work.) is prepared. After the SRS, HLD(Document about main modules for the software) and
            LLD(Doucment about sub-modules for the softwre).
            After HLD AND LLD- coding begins.(The process till now happen is known as Static testing and to make sure 
            all the document work happen till now is correct and complete, this is ensured by reviews/walkthroughs/inspections.)

            Once coding is completed- software will be entered into testing cycle, where dynamic testing begins.
           White-box testing:
            1)Unit testing- each modules will be tested by developers themselves.
            2)Integration testing- communication bw each modules will be tested by developers.
           Blackbox-testing
            3)System testing- Testers actually entered for the first time here, they will test the actual software is allignment
            with cx's need or not.
            4)User Acceptance Testing: Finally, cx along with testers will test the actual software. Then enters into the production.

        Pros in this model:
            1)Conducting tests in all phases of a cycle will result in no/minimal bugs.
        Cons:
            1)Documentation is more,
            2)Initial investement is more.

    What is review, walkthrough and inspection?
        These are the techniques used in static tests to verify the document of the client's requirements.
        Review- reviewing the BRS/SRS/HLD AND LLD documents to check their correctness and completeness.
        Walkthrough- It's an informal review, does not have any minutes of meet.Author will read the doucment and discuss it 
        with peers.
        Inspection- Formal review, notified via any medium company choose. Minimun 3 people will be part of the meet,
        they are author, writer and moderator.

    QA/QC/QE?

    QA VS QC:

    QA - QA is process oriented who make sures everyone in the SDLC follows the process properly to prevent defects
    in the software.QA for entire SDLC cycle.
    QC-  QC is related to product oriented who tests the actual software to detect the bugs and report to the 
    developer team to fix.QC for one part of SDLC testing cycle.
    QE- A team only with automation testers who write the code to test the software.

Levels of testing:
1)Unit testing- BASIS PATH TESTING:
    In basis path testing, developer will conduct test on each module to make sure all the internal logics in each program is 
correct. Testers will call this as component testing when they test components in the UI.
Control structure testing-a)condtional coverage- developers will test both the codition in a conditional statement.
                          b)Loops coverage- here developer tests the loop statement, whether it is printing 
from the correct and till the last number and print all the required numbers is tested. 
                          c)Mutation testing- testing a code with multiple input.
                          
2)Integration Testing:
    communication between 2 or more modules is tested,
    a)Incremental integration Testing: incrementally adding modules and communication is tested among those models.
        i)top-down approach-incrementally adding modules and flow bw those models along with the new model added is the 
    child of the previous/parent model.i,e-compose is the parent for items in sent. Sent is the parent of the deleted items.

        ii)Bottom up approach-incrementally adding the modules and testing the data flow bw those models along with
    ensure the new model added is the parent of the previous model.
        i,e. deleted is the parent for sent items while sent items are the parent for composed items.
        
        sandwich approach-mix of the both previos models.

    b)non-incremental approach- all the models will be tested in one go.
    cons:
    1)may miss some models data flow bw modules.
    2)difficult to find which module has the bug.

3)System testing-once testers are clear with the requirements of the cx's and the unit and integration is done, actual testers
entered into testing the functionality of the software. 
Testers will test the following things while testing:
1)User interface testing(GUI)
2)Functional testing
3)Non-functional testing(Perform-ance,security and etc.)
4)Usablity testing(User help/user manuals)

4)User acceptance testing- client's will test the software.
Alpha testing- cx will test the software at the development environment.
Beeta testing- cx will install the software at their environment and do some basic test and then software enters into the production.


System testing:

    Once testers are cleared with the requirements, they enter into the sytem testing phase where there are 4 tests conducted.

1)GUI testing:
    User interface of the application is tested. Testers will prepare the GUI checklist and test according to it.
    Testers will test the elements in the User face by giving different inputs and observe their behaviour.


2)Usability Testing:
    User friendly application.(Testers will go through the help menu/user manual of the software and ensure the document can be
    understood by non-technical people.). User manual is prepared by the developers.

3)Functional Testing: Functionality is nothing but how application and it's features behave. Testers will test whether 
those features function according to the requirements or not.

    a)Object properties testing: Characteristics of the object in the UI is tested here.
    i,e. enabled/disabled, focused or not, visible or not and etc.
    b)Database Testing/Backend testing: (Database is a storage area where all the datas are stored.)
        As a tester, we will first focus on DML(Data Manipulation Language) operations. In this testing, testers will observe
    how database is behaving when testers checking UI by inserting, updating ,deleting, submitting and selecting data at the UI level.
    In database testing, testing the UI is blackbox, while checking the database comes under the whitebox. Combination of 
    whitebox and blackbox testing known as greybox testing, database is an example of greybox.

    Whitebox testing in database=In this testing , the tables will be also tested(Table and column level validation)-column type,column length,number of columns in the
    table), relation bw tables(Normalization),functions, procedures,triggers, indexes,views and etc.

    c)Error Handling Testing: Testers will verify how software is displaying msg when given invalid actions.
    That error message should be readale by users/non-technical people.

    d)Calculations and manipulation testing:
        Calculations testing will be conducted by both valid and invalid data's. And calculations are mostly used in
        financial applications like banking.

    e)Links existence/Links execution(If web applications):
    Must focus on:
        Link position according to the document- Link existence
        Link execution - whether it is navigating to proper page or not.

        Types of link in web pages:
        1)Internal link- navigate to another section in the same page.
        2)External- navigate to another page.
        3)Broken- Will not leave to any link.(For future use, if the client want them to navigate to other page/same page
         in different section.)
         In GUI- we verifying the color and position(also color change).
    f)Cookies and session(If web application):

        Cookies are temporary files created by browser while browsing the pages  through internet.
    Whether web application saves/remembers cookies or not is knowm as testing.

        Session- timeslot will be started at the server end to count inactiveness.(This is mostly used in banking applications
    ,to ensure the security of the user, the server will close the application/end the session on behalf of the user.)



Non-functional testing: Once the functionality is stable, then non-functional testing will be conducted. This type of 
testing done for cx's expection not for cx's requirement.

    a)Performance testing: Specific team will be there to conduct the performance testing like security testing.
    In performance testing, the speed of the application will be tested. Performance testing will be conducted in 3 ways.
        Note:Performance testing will be conducted for only web applications.
        i)Load-Incrementally/gradually increase the count of user's, on the other end the speed is tested while user count increase.
        ii)Stress-Suddently increase/decrease the load and check the speed at the other end.
        iii)Volume- How much data can be handled by web application.
        

    b)Security testing:The security of the application tested.

    Authentication and Authorization is tested.

    Authentication-The user is valid or not, if valid, the application should allow them to use the application and access
    his certain data and functions.
    Authorization or acccess control-Permission of the valid user is tested.

    c)Recovery Testing- Data recovery after delete/lose, whether the application can recover that data or not.
    Recovery mechanism is tested if exist.

    d)Compatablity testing- the software working on differnt interfaces.

        three types of compatablity:
        i)Forward compatablity- If I update my app to new version, it should compatable with my existing device instead it
        should not demand for a new device.
        ii)Backward compatablity- If I update my app to new version on my existing device, it should install and work 
        perfectly though I have upgraded device in the market, this is called backward compatablity.
        iii)Hardware compatablity/configuration testing-software should be installed and worked on multiple kind of hardware environment.
    
    e)Installation testing- we have to just test the installation testing and while installing, screens are easy to understand or not.
    Similary uninstallation process- after installation, whether all file belonged to the software removed or not

    f)Sanitation/Garbage testing-finding and reporting the extra functionalities/features in the application to the developer
    and remove is known as sanitation or garbage testing.
    Those extra functionalities will be considered as a bug.
    

Software Testing Terminologies:
    Regression Testing: After the developer fixed the bug in a module, there should not  be any impace in the data flow bw other modules.
Testing about this impact is known as regression testing.
    a)Unit Regression Testing:
        Testing only the changes/modifications done by the developer.
    b)Reasonal Regression Testing:
        Testing the modified module along with impacted modules.
        Impact analysis meeting conducts to identify impacted modules with QA &Tester.
    c)Full Regression:
        Testing the main feature & remaining part of the application.
        i,e. Developer  might make the changes to almost in entire application, so we need to conduct full testing.

    Re-Testing:
        If the tester validating/check for the bug reported earlier fixed or not is known as Re-Testing.
        Here only testing the reported bug or not while regression testing may require to test the impacted modules.
        
    Smoke and Sanity Testing:
        Note:build means developer team will give a piece of software which contains some features.
        3rd image contains smoke and sanity testing details. Remaining tests will start only after the bill passed smoke and sanity.
    Exploratory Testing:
        This type of testing is conducted by the testers withour any requirement document, this is done like exploring the 
    application like a cx. Software is ready but documentation is not complete.
    Con: There might be chance to misunderstood a feature as bug and vice versa.
         Will take much time.
     
     This testing adavanatage is harnessed only by the experienced testers who can complete the work quick and in a good way.
     
     AD Hoc testing:
        This is an informal testing, can be conducted anytime to check the entire part of the appkication without any doucmentation work and
    test cases.Here the application will be tested randomly. Tester should have knowledge in the application.

    Monkey/Gorila Testing:
        Without any prior knowledge of application, even without documentation and test cases, testing the application is
    known as Monkey testing.Also informal.

        Suitable for gaming applications.

    Positive Testing:
        The application is tested by giving positive inputs(Valid) to the application to check whether the application is 
    behaving as expected or not.
    Negative Testing: Testing the application with negative inputs.
    i,e= Enter only numbers:182938(+ive)
        Enter only numbers:abcd(-ive)

    End to End Testing:
        Testing the overall functionality of the application including the data integration  among all modules is called end
    end testing.
    ie. Login- Add cx- Edit cx- Delete cx- Logout(So every flow/Major functionality of the application is covered of the application.)

    Note:Globalization testing also known as I18N testing.


Test Data Techniques/Test case design Techniques:
1)Used to prepare data for testing.
2)Coverage(whatever data we prepared by using which we can cover all the test scenarios).

    Types in test design techniques/preparing the test data:
        1)Equilence Class Partioning(ECP):(Here we will focus on values whether it is alphabets, numberics or special characters.)
            We will classify one huge data into multiple classes and test randomly.For an example,
                there is a textbox which will allow numbers from one to 10, then we don't need to test all the numbers
            from 0 to 100, instead, we take a number from -10 to 0(which is actually invalid data) and then we take one number
            from each 10 and test till 100-110. This partion technique reduces test data to test so it saves time.

        2)  Boundary Value Analysis(BVA):
             I have to enter input for age bw 18-30:
                We will only here test the boundaries, for an example, 18,30,(18-1) and (18+1), (30-1) and (30+1).
                here along with 2 boundaries, min-1 and +1 and max-1,+1 is tested.

        Input domain testing: will be conducted with ECP and BVA in the input field boxes/ textbox.(In this method, the value we
        are entering in the field box  will be verified )

        Decision table/ also known as cause-effect table:
            This technique is used if we have more number of condions and corresponding actions.

            For an example, take an example of sending money online to an account which is already added and approved.
            Here are the conditions to send money online:
            a)Account is approved,
            b)OTP is matching,
            c)Sufficient money in the account.

            Here are the actions to be performed:
            a)Transfer Money.
            b)Show as insufficient message
            c)Block the transaction incase of there is any suspicious activity found.
        
        4)State Transition:
            In state transition technique changes in input conditions change the state of the application.(6th picture is an
            example.)
            This technique allows the tester to test the behaviour of an AUT. Testers can perform this actions by entering 
            different input conditions in a sequence. In this technique, testing team provides both positive as well as negative
            input test values for evaluating the system behaviour.
            (Refer the 6th picture.)

        5)Error guessing:
             It's a minor technique, used to track the bug by the guessing of testers analytical skills.
             for an example, experienced testers would find the bug just by using the appkication.

            
         Software Testing Life Cycle(STLC)- This is part of SDLC.
            1)Understanding requirement
            2)Test planning
            3)Test design
            4)Test Execution
            5)Track and report the bugs and report it to the developer team.
            6)Test closure.


        Terminologies: Use cases- describes the requirement in diagram format which will be easy to understood.
        test scenarios- what are the areas to be tested is comes under test scenerios. For example, login is one area, 
        if both user name and password correct then allow login, this is one scenario, like this we can create multiple scenario
        of test cases.
        test case- step by step procedure we have to follow to test the application.
        we can create multiple test cases for one scenario.
        Peer review- whatever test cases completed is completed will be discussed with team so we can make sure, we didn't 
        miss any testcases.
        Tracablity Matrix(Mapping document)- mapping bw requirement and testcases. This will say what are the test cases I covered and I not if any.
        Sign-off:
            Developer team, managers will give sign off to kick start the exection of test cases.

        smoke testcases>sanitary>functionality

        Test Log: Testers will keep this document about the status of the executed testcases, how many cases are passed and 
        how many failed.

        Identifying and reporting bugs to the developer team is also comes under test execution.


         p1 bugs- priority 1 bug which has to be fixed immediately.
         P2- Major
         p3- Minor.
         


         Terminologies in Detail:
         1)Suspension and resumption criteria:
            We will stop testing when the application is broken and resume after the recovery/got a new bill from the
            developer team.
        Use cases will be created by product managers and others not by testers.

        Test suite- group of test cases
        for an example, functionalities will be part of test suite 1
        regression test cases are part of test suite 2
        smoke testing is 3 suite..


        
    Requirement Traceblity Matrix:
        By this we can ensure, all the requirement's test cases are completed. The main purpose of the RTM is to see that all the
        test cases are completed so no test cases for requirement is left over.

        RTM parameters include:1)Requirement id 2)requirement description  3)testcase id 

    Test Environment/Test bed:
        We should make preparation to setup software and hardware which should be same as cx's using environment(cx software
        and hardware, including the database.)- Simply understand the cx's environmet and recreate it and then start testing.

    Bug tracking tools vs Test management tools:
    Bug tracking tools are only to report bugs while test management tools do not only bug tracking but also entire
    test management cycle will be updated in this tool of test management. Test management tools examples are JIRA and QUALITY CENTER.
    Bug tracking tools are CLEAR QUEST, BUG JILLA and DEV TRACK.

    Tester will assign severity and priority to a bug. Priority can be changed by test managers, business people and 
    even by developers sometimes but severity could be changed only by the tester.

    Defect Resolution:
        Developer will update his opinion on bug raised by the devloper.

        IF bug resolution says it's duplicate- then this bug already raised.
        if enchancement then it's not a bug instead a feature.
        if need more information then we need to give screenshots and log file etc about the bug.
        if not reproducable then it means bug only found at testers environment not at developer environment.
        if accept- then developer accepted it as a bug.
        if reject- then developer rejected to consider it as a bug.
        if fixed- then developer fixed the bug.
        if as assigned- developer team will report it should work in that way only, so it is not a bug.
        if deferred then the bug is new so developer team will put it in the queue.
        if assigned means the developer assigned to fix the bug.
        if open- then developer start to fixing the bug.
        if the bug again not fixed we will pass it to the developer to fix it again, the status will go reopen.
        if bug fixed and passed then status will go closure.
        enchancement means it's a extra feature which clients wish to implement in the near future.
    
    Defect/Bug Life Cycle:
        This will always tell us what is the status of the bug.

    Reasons behind developer rejecting a raised bug:
    enchancement- need more info-not reproducable-as designed.
    
    Closure- Final phase of testing.
    




